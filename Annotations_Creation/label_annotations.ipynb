{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQADpBDE/jKuUzz3cR1fX6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/PitVQA_Annotations/blob/main/Annotations_Creation/label_annotations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part1: generate images: This part is to transfer video to images\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pWxNjPm5phus"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYSCIuZkpegy"
      },
      "outputs": [],
      "source": [
        "# global imports\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# strong typing\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "from time import time\n",
        "from google.colab import drive\n",
        "'''\n",
        "Before run this code, your folder system should look like this:\n",
        "project-name/\n",
        "├── videos/\n",
        "│   ├── video_01.mp4\n",
        "│   └── video_02.mp4\n",
        "│   └── ...\n",
        "│   └── video_25.mp4\n",
        "├── images/\n",
        "├── video_to_images.py\n",
        "note: 'images' is an empty folder before running this code.\n",
        "'''\n",
        "\n",
        "def main():\n",
        "    \"\"\"required variables are {pt_videos} and {pt_images}\"\"\"\n",
        "    # Mount Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Update paths to point to Google Drive\n",
        "    pt_videos = Path(\"/content/drive/My Drive/annotations/videos\")# Replace your own address here\n",
        "    pt_images = Path(\"/content/drive/My Drive/annotations/images\")# Replace your own address here\n",
        "\n",
        "    st = time()\n",
        "    convert_videos_to_images(pt_videos=pt_videos, pt_images=pt_images)\n",
        "    et = time()\n",
        "    print(f'time used: {et-st}')\n",
        "\n",
        "def convert_videos_to_images(pt_videos: Path, pt_images: Path):\n",
        "    \"\"\"convert all videos from {pt_videos} to images saved to {pt_images}\"\"\"\n",
        "    create_directory(pt=pt_images)\n",
        "\n",
        "    ls_videos: List[str] = os.listdir(pt_videos)\n",
        "    ls_videos.sort()\n",
        "\n",
        "    for str_video in ls_videos:\n",
        "        pt_video: Path = pt_videos.joinpath(str_video)\n",
        "        pt_image: Path = pt_images.joinpath(str_video.split(\".\")[0])\n",
        "\n",
        "        create_directory(pt=pt_image)\n",
        "        convert_video_to_image(pt_video=pt_video, pt_image=pt_image)\n",
        "        print(f'{str_video} finished.')\n",
        "\n",
        "def convert_video_to_image(pt_video: Path, pt_image: Path):\n",
        "    \"\"\"convert a single video from {pt_video} to images saved to {pt_image}\"\"\"\n",
        "    video_capture = cv2.VideoCapture(str(pt_video))\n",
        "    int_frames_per_second: int = np.ceil(video_capture.get(cv2.CAP_PROP_FPS))  # ceiling function to ensure integer\n",
        "\n",
        "    int_frame: int = 0\n",
        "    while video_capture.isOpened():\n",
        "        bool_success, np_frame_matrix = video_capture.read()\n",
        "        if bool_success:\n",
        "            if int_frame % int_frames_per_second == 0:\n",
        "                pt_image_frame: Path = pt_image.joinpath(f\"{int(int_frame / int_frames_per_second):05}.png\")\n",
        "                cv2.imwrite(str(pt_image_frame), np_frame_matrix)\n",
        "                print(\"written\")\n",
        "        else:\n",
        "            break\n",
        "        int_frame += 1\n",
        "\n",
        "    video_capture.release()\n",
        "\n",
        "    print(f\"{pt_video} successfully converted to {int_frame} images.\")\n",
        "\n",
        "def create_directory(pt: Path):\n",
        "    \"\"\"create a directory for a given {path} if it does not already exist\"\"\"\n",
        "    if not os.path.exists(pt):\n",
        "        os.mkdir(pt)\n",
        "\n",
        "main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part2: Image process: This part is to process the images"
      ],
      "metadata": {
        "id": "Z6xCZvBcpwxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from PIL import Image, ImageOps\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "'''\n",
        "Before run this code, your folder system should look like this:\n",
        "project-name/\n",
        "├── images/\n",
        "│   ├── video_01/\n",
        "│   └── video_02/\n",
        "│   └── ...\n",
        "│   └── video_25/\n",
        "├── preprocessed_images/\n",
        "├── preprocess_images.py\n",
        "note: 'preprocessed_images' is an empty folder before running this code.\n",
        "'''\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Mount Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Update paths to point to Google Drive\n",
        "    base_path = Path(\"/content/drive/My Drive/annotations\") # Repalce your own address here\n",
        "    images_path = base_path / 'images'\n",
        "    output_path = base_path / 'preprocessed_images'\n",
        "\n",
        "    # Specify video sequences\n",
        "    video_sequence = [f\"video_{i:03}\" for i in [18, 19, 33, 35]] # Modify this palce according to your own video index\n",
        "\n",
        "    for seq in video_sequence:\n",
        "        folder_path = images_path / seq\n",
        "        images = folder_path.glob('*.png')\n",
        "\n",
        "        # Create a new folder (e.g., video_01/) in the 'preprocessed_images' folder\n",
        "        new_folder = output_path / seq\n",
        "        new_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        for img in images:\n",
        "            image = Image.open(img)\n",
        "\n",
        "            # Process images\n",
        "            crop_box = (295, 50, 935, 690)\n",
        "            cropped_image = image.crop(crop_box)  # Crop images\n",
        "            resized_image = cropped_image.resize((224, 224), Image.BICUBIC)  # Resize images\n",
        "\n",
        "            # Save processed images\n",
        "            save_path = new_folder / img.name\n",
        "            resized_image.save(save_path)\n",
        "        print(seq + ' done.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L0tJtrlp4qt",
        "outputId": "4a810fe6-0607-49f2-913b-e42e83fe66f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "video_018 done.\n",
            "video_019 done.\n",
            "video_033 done.\n",
            "video_035 done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part3: Text files generation: This part is to create the empty QA text files for each video"
      ],
      "metadata": {
        "id": "YG_iJ9wjnDX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# path to images folder\n",
        "images_folder = Path(\"/content/drive/My Drive/annotations/images\")\n",
        "# path to QA folder\n",
        "qa_folder = Path(\"/content/drive/My Drive/annotations/QA\")\n",
        "\n",
        "# create QA folder if needed\n",
        "qa_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# go through images folder\n",
        "for folder in images_folder.iterdir():\n",
        "    if folder.is_dir():\n",
        "        folder_path = folder  # images/video_01\n",
        "\n",
        "        # create counterpart sub-folder in QA folder\n",
        "        qa_subfolder_path = qa_folder / folder.name  # QA/video_01\n",
        "        qa_subfolder_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # create txt file for each image\n",
        "        for file in folder.iterdir():\n",
        "            if file.suffix == '.png':\n",
        "                txt_filename = file.stem + '.txt'\n",
        "                txt_filepath = qa_subfolder_path / txt_filename\n",
        "                txt_filepath.touch()\n"
      ],
      "metadata": {
        "id": "ia6lE_m7nmVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part4：Instruments file generation: To finish the labeling work, instruments files and video files is compulsory. If you have these two kinds of files, please go to Part 6. Otherwise, please run the code from part4 and part5 first to generate intruments filess and steps files with the annotation file like in the image below:\n",
        "\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "To run this part, you also need the map_instruments.csv file which can be found tin the meta_data folder of this repository\n"
      ],
      "metadata": {
        "id": "v8d2H-4zpEFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "def generate_instruments_csv_batch():\n",
        "    # Define file paths, replace your own address here\n",
        "    input_folder = Path(\"/content/drive/My Drive/annotations/annotation_files\")\n",
        "    mapping_file = Path(\"/content/drive/My Drive/map_instruments.csv\")\n",
        "    output_folder = Path(\"/content/drive/My Drive/annotations/instruments\")\n",
        "\n",
        "    # Ensure output folder exists\n",
        "    output_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Load mapping file\n",
        "    try:\n",
        "        mapping_df = pd.read_csv(mapping_file, encoding='utf-8')\n",
        "    except UnicodeDecodeError:\n",
        "        mapping_df = pd.read_csv(mapping_file, encoding='ISO-8859-1')\n",
        "\n",
        "    # Create mapping dictionary\n",
        "    instrument_mapping = dict(zip(mapping_df['int_instrument'], mapping_df['str_instrument']))\n",
        "\n",
        "    # Process each annotations file in the input folder\n",
        "    for annotations_file in input_folder.glob(\"annotations_*.csv\"):\n",
        "        try:\n",
        "            # Load annotations file\n",
        "            annotations_df = pd.read_csv(annotations_file, encoding='utf-8')\n",
        "        except UnicodeDecodeError:\n",
        "            annotations_df = pd.read_csv(annotations_file, encoding='ISO-8859-1')\n",
        "\n",
        "        # Create a copy of the annotations data to process\n",
        "        processed_df = annotations_df.copy()\n",
        "\n",
        "        # Map int_instrument1 and int_instrument2 to their string representations\n",
        "        processed_df['str_instrument1'] = processed_df['int_instrument1'].map(instrument_mapping)\n",
        "        processed_df['str_instrument2'] = processed_df['int_instrument2'].map(instrument_mapping)\n",
        "\n",
        "        # Add empty columns for pos_instrument1 and pos_instrument2\n",
        "        processed_df['pos_instrument1'] = ''\n",
        "        processed_df['pos_instrument2'] = ''\n",
        "\n",
        "        # Rearrange the column order\n",
        "        output_columns = [\n",
        "            'int_video',\n",
        "            'int_time',\n",
        "            'str_instrument1',\n",
        "            'str_instrument2',\n",
        "            'int_instrument1',\n",
        "            'int_instrument2',\n",
        "            'pos_instrument1',\n",
        "            'pos_instrument2'\n",
        "        ]\n",
        "\n",
        "        # Modify output file name\n",
        "        output_file_name = annotations_file.name.replace(\"annotations_\", \"instruments_\")\n",
        "        output_file = output_folder / output_file_name\n",
        "\n",
        "        # Save the generated CSV file\n",
        "        processed_df[output_columns].to_csv(output_file, index=False)\n",
        "\n",
        "        print(f\"File successfully generated: {output_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_instruments_csv_batch()\n"
      ],
      "metadata": {
        "id": "7AWT_FrnrEpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part5：Steps file generation: To finish the labeling work, instruments files and video files is compulsory. If you have these two kinds of files, please go to Part 6. Otherwise, please run the code from part4 and part5 first to generate intruments filess and steps files with the annotation file.\n",
        "To run this part, you also need the map_steps.csv file which can be found tin the meta_data folder of this repository"
      ],
      "metadata": {
        "id": "t7gjS4tvuJ8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "def generate_step_csv_batch():\n",
        "    # Define file paths\n",
        "    input_folder = Path(\"/content/drive/My Drive/annotations/annotation_files\")\n",
        "    steps_mapping_file = Path(\"/content/drive/My Drive/map_steps.csv\")\n",
        "    output_folder = Path(\"/content/drive/My Drive/steps\")\n",
        "\n",
        "    # Ensure output folder exists\n",
        "    output_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Load mapping file\n",
        "    steps_mapping_df = pd.read_csv(steps_mapping_file)\n",
        "\n",
        "    # Create mapping dictionary\n",
        "    step_mapping = dict(zip(steps_mapping_df['int_step'], steps_mapping_df['str_step']))\n",
        "\n",
        "    # Process each annotations file in the input folder\n",
        "    for annotations_file in input_folder.glob(\"annotations_*.csv\"):\n",
        "        # Load annotations file\n",
        "        annotations_df = pd.read_csv(annotations_file)\n",
        "\n",
        "        # Initialize result list\n",
        "        results = []\n",
        "\n",
        "        # Get initial row information\n",
        "        previous_step = None\n",
        "        start_time = None\n",
        "        int_video = annotations_df['int_video'].iloc[0]  # Assume all rows have the same int_video\n",
        "\n",
        "        # Iterate through annotations_df\n",
        "        for index, row in annotations_df.iterrows():\n",
        "            current_step = row['int_step']\n",
        "            current_time = row['int_time']\n",
        "\n",
        "            # Detect step change\n",
        "            if previous_step is None:\n",
        "                previous_step = current_step\n",
        "                start_time = current_time\n",
        "            elif current_step != previous_step:\n",
        "                # Save change information\n",
        "                results.append({\n",
        "                    'int_video': int_video,\n",
        "                    'int_time': start_time,\n",
        "                    'str_step': step_mapping.get(previous_step, 'Unknown'),\n",
        "                    'int_step': previous_step\n",
        "                })\n",
        "                # Update start time and current step\n",
        "                previous_step = current_step\n",
        "                start_time = current_time\n",
        "\n",
        "        # Add the last step's information\n",
        "        if previous_step is not None:\n",
        "            results.append({\n",
        "                'int_video': int_video,\n",
        "                'int_time': start_time,\n",
        "                'str_step': step_mapping.get(previous_step, 'Unknown'),\n",
        "                'int_step': previous_step\n",
        "            })\n",
        "\n",
        "        # Convert results to DataFrame\n",
        "        results_df = pd.DataFrame(results)\n",
        "\n",
        "        # Modify output file name\n",
        "        output_file_name = annotations_file.name.replace(\"annotations_\", \"steps_\")\n",
        "        output_file = output_folder / output_file_name\n",
        "\n",
        "        # Save to CSV file\n",
        "        results_df.to_csv(output_file, index=False)\n",
        "\n",
        "        print(f\"File successfully generated: {output_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_step_csv_batch()\n"
      ],
      "metadata": {
        "id": "uEQPjakEt_xH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part6: Labeling: This code is to label the images with QA pairs. In this part the empty QA txt files will be filled with QA pairs."
      ],
      "metadata": {
        "id": "PxtWfOdHuXLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# try:\n",
        "#     from utils import (step_phase_mapping, next_step_mapping, next_phase_mapping,\n",
        "#                        step_operation_mapping, number_location_mapping)\n",
        "# except ImportError:\n",
        "#     import sys\n",
        "#     sys.path.append('D:\\\\MSc Dataset\\\\Annotaion18193335\\\\utils.py')\n",
        "#     from utils import (step_phase_mapping, next_step_mapping, next_phase_mapping,\n",
        "#                        step_operation_mapping, number_location_mapping)\n",
        "\n",
        "count_dict = {}\n",
        "frames = 0\n",
        "questions = 0\n",
        "\n",
        "def step_phase_mapping(step_name):\n",
        "    if step_name in ['nasal corridor creation', 'anterior sphenoidotomy', 'septum displacement', 'sphenoid sinus clearance']:\n",
        "        return 'nasal sphenoid'\n",
        "    elif step_name in ['sellotomy', 'durotomy', 'tumour excision']:\n",
        "        return 'sellar'\n",
        "    elif step_name in ['haemostasis', 'synthetic graft placement', 'fat graft placement',\n",
        "                       'gasket seal construct', 'dural sealant', 'nasal packing', 'debris clearance']:\n",
        "        return 'closure'\n",
        "    elif step_name in ['operation not started', 'operation ended', 'out of patient']:\n",
        "        return 'UNDEFINED PHASE: the step is not 1 of 14 steps'\n",
        "    else:\n",
        "        return 'Unknown phase'\n",
        "\n",
        "def next_step_mapping(current_step):\n",
        "    steps = [\n",
        "        'nasal corridor creation', 'anterior sphenoidotomy', 'septum displacement', 'sphenoid sinus clearance',\n",
        "        'sellotomy', 'durotomy', 'tumour excision', 'haemostasis', 'synthetic graft placement',\n",
        "        'fat graft placement', 'gasket seal construct', 'dural sealant', 'nasal packing', 'debris clearance'\n",
        "    ]\n",
        "    if current_step in steps:\n",
        "        idx = steps.index(current_step)\n",
        "        return steps[idx + 1] if idx + 1 < len(steps) else 'end of step'\n",
        "    elif current_step == 'operation not started':\n",
        "        return 'Current step is operation not started'\n",
        "    elif current_step == 'operation ended':\n",
        "        return 'Current step is operation ended'\n",
        "    elif current_step == 'out of patient':\n",
        "        return 'Current step is out of patient'\n",
        "    else:\n",
        "        return 'Unknown next step'\n",
        "\n",
        "def next_phase_mapping(current_phase):\n",
        "    if current_phase == 'nasal sphenoid':\n",
        "        return 'sellar'\n",
        "    elif current_phase == 'sellar':\n",
        "        return 'closure'\n",
        "    elif current_phase == 'closure':\n",
        "        return 'end of phase'\n",
        "    elif current_phase == 'UNDEFINED PHASE: the step is not 1 of 14 steps':\n",
        "        return 'Invalid current phase'\n",
        "    else:\n",
        "        return 'Unknown phase'\n",
        "\n",
        "def step_operation_mapping(step_name):\n",
        "    operations = {\n",
        "        'nasal corridor creation': 'The middle and superior turbinates are laterally displaced',\n",
        "        'anterior sphenoidotomy': 'The sphenoid ostium is identified and opened',\n",
        "        'septum displacement': 'The septum is displaced until the opposite ostium is seen',\n",
        "        'sphenoid sinus clearance': 'The sphenoid sinus is opened, with removal of sphenoid septations to expose the face of the sella and mucosa',\n",
        "        'sellotomy': 'The sella is identified, confirmed and carefully opened',\n",
        "        'durotomy': 'A cruciate durotomy is performed',\n",
        "        'tumour excision': 'The tumour is seen and removed in a piecemeal fashion',\n",
        "        'haemostasis': 'Haemostasis is achieved with a surgiflo, a bipolar cautery, and a spongostan placement',\n",
        "        'synthetic graft placement': 'spongostan, tachosil and duragen placement',\n",
        "        'fat graft placement': 'A fat graft is placed over the defect',\n",
        "        'gasket seal construct': 'A MedPor implant and a fascia lata graft are placed',\n",
        "        'dural sealant': 'Evicel and Adherus dural sealant are applied',\n",
        "        'nasal packing': 'The nasal cavity is packed with Bismuth soaked ribbon gauze',\n",
        "        'debris clearance': 'Debris is cleared from the nasal cavity and choana',\n",
        "        'operation not started': 'UNDEFINED OPERATION',\n",
        "        'operation ended': 'UNDEFINED OPERATION',\n",
        "        'out of patient': 'UNDEFINED OPERATION',\n",
        "    }\n",
        "    return operations.get(step_name, 'Unknown operation')\n",
        "\n",
        "def number_location_mapping(location_code):\n",
        "    locations = {\n",
        "        '1.0': 'top-left',\n",
        "        '2.0': 'top-right',\n",
        "        '3.0': 'centre',\n",
        "        '4.0': 'bottom-left',\n",
        "        '5.0': 'bottom-right',\n",
        "    }\n",
        "    return locations.get(location_code, 'Unknown location')\n",
        "\n",
        "\n",
        "def prepare_what_phase_qa(step_name):\n",
        "    question = 'What is the surgical phase shown in the image?'\n",
        "    answer = 'The surgical phase shown in the image is ' + step_phase_mapping(step_name) + '.'\n",
        "    qa = question + '|' + answer\n",
        "    if answer not in count_dict.keys():\n",
        "        count_dict[answer] = 1\n",
        "    else:\n",
        "        count_dict[answer] += 1\n",
        "    return qa, answer\n",
        "\n",
        "\n",
        "def prepare_what_step_qa(step_name):\n",
        "    question = 'What is the surgical step shown in this frame?'\n",
        "    answer = 'The surgical step shown in the image is ' + step_name + '.'\n",
        "    qa = question + '|' + answer\n",
        "    if answer not in count_dict.keys():\n",
        "        count_dict[answer] = 1\n",
        "    else:\n",
        "        count_dict[answer] += 1\n",
        "    return qa\n",
        "\n",
        "\n",
        "def prepare_next_phase_qa(current_phase):\n",
        "    question = 'What is the next surgical phase?'\n",
        "    answer = 'The next surgical phase is ' + next_phase_mapping(current_phase)+ '.'\n",
        "    qa = question + '|' + answer\n",
        "    if answer not in count_dict.keys():\n",
        "        count_dict[answer] = 1\n",
        "    else:\n",
        "        count_dict[answer] += 1\n",
        "    return qa\n",
        "\n",
        "\n",
        "def prepare_next_step_qa(current_step):\n",
        "    question = 'What is the next surgical step?'\n",
        "    answer = 'The next surgical step is ' + next_step_mapping(current_step)+ '.'\n",
        "    qa = question + '|' + answer\n",
        "    if answer not in count_dict.keys():\n",
        "        count_dict[answer] = 1\n",
        "    else:\n",
        "        count_dict[answer] += 1\n",
        "    return qa\n",
        "\n",
        "\n",
        "def prepare_how_many_tool_qa(num_of_tool):\n",
        "    question = 'How many instruments are present in the image?'\n",
        "    answer = f'{num_of_tool} instruments are present in the image.'\n",
        "    if num_of_tool == 0:\n",
        "        answer = 'No instrument is present in the image.'\n",
        "    elif num_of_tool == 1:\n",
        "        answer = 'One instrument is present in the image.'\n",
        "    elif num_of_tool == 2:\n",
        "        answer = 'Two instruments are present in the image.'\n",
        "    qa = question + '|' + answer\n",
        "    if answer not in count_dict.keys():\n",
        "        count_dict[answer] = 1\n",
        "    else:\n",
        "        count_dict[answer] += 1\n",
        "    return qa\n",
        "\n",
        "\n",
        "def prepare_what_operation_qa(step_name):\n",
        "    question = 'What is the surgical operation performed in the image?'\n",
        "    answer = 'The surgical operation performed in the image is: \"' + step_operation_mapping(step_name) +'.\"'\n",
        "    qa = question + '|' + answer\n",
        "    if answer not in count_dict.keys():\n",
        "        count_dict[answer] = 1\n",
        "    else:\n",
        "        count_dict[answer] += 1\n",
        "    return qa, answer\n",
        "\n",
        "\n",
        "def prepare_what_tool_qa_one(row_content):\n",
        "    # What instrument is used in the bottom-mid of the image? | 1 of 18 instruments\n",
        "    qa = 0\n",
        "    if pd.notna(row_content['pos_instrument1']):\n",
        "        if str(row_content['pos_instrument1']) == '3.0':\n",
        "            question = 'What instrument is used at the centre of the image?'\n",
        "            answer = f\"The instrument present at the center of the image is {row_content['str_instrument1']}.\"\n",
        "            qa = question + '|' + answer\n",
        "            if answer not in count_dict.keys():\n",
        "                count_dict[answer] = 1\n",
        "            else:\n",
        "                count_dict[answer] += 1\n",
        "        else:\n",
        "            position = number_location_mapping(str(row_content['pos_instrument1']))\n",
        "            question = f'What instrument is used in the {position} of the image?'\n",
        "            answer =  f\"The instrument present in the {position} of the image is {row_content['str_instrument1']}.\"\n",
        "            qa = question + '|' + answer\n",
        "            if answer not in count_dict.keys():\n",
        "                count_dict[answer] = 1\n",
        "            else:\n",
        "                count_dict[answer] += 1\n",
        "    elif pd.notna(row_content['pos_instrument2']):\n",
        "        if str(row_content['pos_instrument2']) == '3.0':\n",
        "            question = 'What instrument is used at the centre of the image?'\n",
        "            answer = f\"The instrument present at the center of the image is {row_content['str_instrument2']}.\"\n",
        "            qa = question + '|' + answer\n",
        "            if answer not in count_dict.keys():\n",
        "                count_dict[answer] = 1\n",
        "            else:\n",
        "                count_dict[answer] += 1\n",
        "        else:\n",
        "            position = number_location_mapping(str(row_content['pos_instrument2']))\n",
        "            question = f'What instrument is used in the {position} of the image?'\n",
        "            answer = f\"The instrument present in the {position} of the image is {row_content['str_instrument2']}.\"\n",
        "            qa = question + '|' + answer\n",
        "            if answer not in count_dict.keys():\n",
        "                count_dict[answer] = 1\n",
        "            else:\n",
        "                count_dict[answer] += 1\n",
        "    return qa\n",
        "\n",
        "\n",
        "def prepare_tool_operation_qa(row_content, operation):\n",
        "    # What surgical activity is performing by the instrument kerrisons? | 1 of 14 operations\n",
        "    qa = 0\n",
        "    if pd.notna(row_content['pos_instrument1']):\n",
        "        tool = row_content['str_instrument1']\n",
        "        question = f'What surgical activity is performing by the instrument {tool}?'\n",
        "        answer = operation+ '.'\n",
        "        qa = question + '|' + answer\n",
        "        if answer not in count_dict.keys():\n",
        "            count_dict[answer] = 1\n",
        "        else:\n",
        "            count_dict[answer] += 1\n",
        "    elif pd.notna(row_content['pos_instrument2']):\n",
        "        tool = row_content['str_instrument2']\n",
        "        question = f'What surgical activity is performing by the instrument {tool}?'\n",
        "        answer = operation+ '.'\n",
        "        qa = question + '|' + answer\n",
        "        if answer not in count_dict.keys():\n",
        "            count_dict[answer] = 1\n",
        "        else:\n",
        "            count_dict[answer] += 1\n",
        "    return qa\n",
        "\n",
        "\n",
        "def prepare_where_tool_qa(row_content):\n",
        "    # Where is the surgical instrument kerrisons tip located in the image? | 1 of 5 locations\n",
        "    qa = 0\n",
        "    if pd.notna(row_content['pos_instrument1']):\n",
        "        tool = row_content['str_instrument1']\n",
        "        question = f'Where is the surgical instrument {tool} tip located in the image?'\n",
        "        answer = f\"The surgical instrument {tool} tip is located at {number_location_mapping(str(row_content['pos_instrument1']))}.\"\n",
        "        qa = question + '|' + answer\n",
        "        if answer not in count_dict.keys():\n",
        "            count_dict[answer] = 1\n",
        "        else:\n",
        "            count_dict[answer] += 1\n",
        "    elif pd.notna(row_content['pos_instrument2']):\n",
        "        tool = row_content['str_instrument2']\n",
        "        question = f'Where is the surgical instrument {tool} tip located in the image?'\n",
        "        answer = f\"The surgical instrument {tool} tip is located at {number_location_mapping(str(row_content['pos_instrument2']))}.\"\n",
        "        qa = question + '|' + answer\n",
        "        if answer not in count_dict.keys():\n",
        "            count_dict[answer] = 1\n",
        "        else:\n",
        "            count_dict[answer] += 1\n",
        "    return qa\n",
        "\n",
        "\n",
        "def prepare_what_tool_qa_two(row_content, col_num):\n",
        "    # What instrument is used in the bottom-mid of the image? | 1 of 18 instruments\n",
        "    qa = 0\n",
        "    if col_num == 1:  # tool 1\n",
        "        if pd.notna(row_content['pos_instrument1']):\n",
        "            if str(row_content['pos_instrument1']) == '3.0':\n",
        "                question = 'What instrument is used at the centre of the image?'\n",
        "                answer = f\"The instrument present at the center of the image is {row_content['str_instrument1']}.\"\n",
        "                qa = question + '|' + answer\n",
        "                if answer not in count_dict.keys():\n",
        "                    count_dict[answer] = 1\n",
        "                else:\n",
        "                    count_dict[answer] += 1\n",
        "            else:\n",
        "                position = number_location_mapping(str(row_content['pos_instrument1']))\n",
        "                question = f'What instrument is used in the {position} of the image?'\n",
        "                answer = f\"The instrument present in the {position} of the image is {row_content['str_instrument1']}.\"\n",
        "                qa = question + '|' + answer\n",
        "                if answer not in count_dict.keys():\n",
        "                    count_dict[answer] = 1\n",
        "                else:\n",
        "                    count_dict[answer] += 1\n",
        "    elif col_num == 2:\n",
        "        if pd.notna(row_content['pos_instrument2']):\n",
        "            if str(row_content['pos_instrument2']) == '3.0':\n",
        "                question = 'What instrument is used at the centre of the image?'\n",
        "                answer = f\"The instrument present at the center of the image is {row_content['str_instrument2']}.\"\n",
        "                qa = question + '|' + answer\n",
        "                if answer not in count_dict.keys():\n",
        "                    count_dict[answer] = 1\n",
        "                else:\n",
        "                    count_dict[answer] += 1\n",
        "            else:\n",
        "                position = number_location_mapping(str(row_content['pos_instrument2']))\n",
        "                question = f'What instrument is used in the {position} of the image?'\n",
        "                answer = f\"The instrument present in the {position} of the image is {row_content['str_instrument2']}.\"\n",
        "                qa = question + '|' + answer\n",
        "                if answer not in count_dict.keys():\n",
        "                    count_dict[answer] = 1\n",
        "                else:\n",
        "                    count_dict[answer] += 1\n",
        "    return qa\n",
        "\n",
        "\n",
        "def prepare_tool_operation_qa_two(row_content, operation, col_num):\n",
        "    # What surgical activity is performing by the instrument kerrisons? | 1 of 14 operations\n",
        "    qa = 0\n",
        "    if col_num == 1:\n",
        "        if pd.notna(row_content['pos_instrument1']):\n",
        "            tool = row_content['str_instrument1']\n",
        "            question = f'What surgical activity is performing by the instrument {tool}?'\n",
        "            answer = operation+'.'\n",
        "            qa = question + '|' + answer\n",
        "            if answer not in count_dict.keys():\n",
        "                count_dict[answer] = 1\n",
        "            else:\n",
        "                count_dict[answer] += 1\n",
        "    elif col_num == 2:\n",
        "        if pd.notna(row_content['pos_instrument2']):\n",
        "            tool = row_content['str_instrument2']\n",
        "            question = f'What surgical activity is performing by the instrument {tool}?'\n",
        "            answer = operation+'.'\n",
        "            qa = question + '|' + answer\n",
        "            if answer not in count_dict.keys():\n",
        "                count_dict[answer] = 1\n",
        "            else:\n",
        "                count_dict[answer] += 1\n",
        "    return qa\n",
        "\n",
        "\n",
        "def prepare_where_tool_qa_two(row_content, col_num):\n",
        "    # Where is the surgical instrument kerrisons tip located in the image? | 1 of 5 locations\n",
        "    qa = 0\n",
        "    if col_num == 1:\n",
        "        if pd.notna(row_content['pos_instrument1']):\n",
        "            tool = row_content['str_instrument1']\n",
        "            question = f'Where is the surgical instrument {tool} tip located in the image?'\n",
        "            answer =  f\"The surgical instrument {tool} tip is located at {number_location_mapping(str(row_content['pos_instrument1']))}.\"\n",
        "            qa = question + '|' + answer\n",
        "            if answer not in count_dict.keys():\n",
        "                count_dict[answer] = 1\n",
        "            else:\n",
        "                count_dict[answer] += 1\n",
        "    elif col_num == 2:\n",
        "        if pd.notna(row_content['pos_instrument2']):\n",
        "            tool = row_content['str_instrument2']\n",
        "            question = f'Where is the surgical instrument {tool} tip located in the image?'\n",
        "            answer =  f\"The surgical instrument {tool} tip is located at {number_location_mapping(str(row_content['pos_instrument2']))}.\"\n",
        "            qa = question + '|' + answer\n",
        "            if answer not in count_dict.keys():\n",
        "                count_dict[answer] = 1\n",
        "            else:\n",
        "                count_dict[answer] += 1\n",
        "    return qa\n",
        "\n",
        "\n",
        "def get_num_of_tool(row_content):  # row_content is the content for that row\n",
        "    if pd.isna(row_content['pos_instrument1']) and pd.isna(row_content['pos_instrument2']):\n",
        "        number_of_tool = 0\n",
        "    elif pd.notna(row_content['pos_instrument1']) and pd.notna(row_content['pos_instrument2']):\n",
        "        number_of_tool = 2\n",
        "    else:\n",
        "        number_of_tool = 1\n",
        "    return number_of_tool\n",
        "\n",
        "\n",
        "def get_current_step_name(step_df, time_list, index):\n",
        "    row_idx = 0\n",
        "    for time in time_list:\n",
        "        if index < time:\n",
        "            row_idx = time_list.index(time)-1\n",
        "            break\n",
        "    step_name = step_df.iloc[row_idx]['str_step']\n",
        "    return step_name\n",
        "\n",
        "\n",
        "def write_file(video_folder, file_name, qa_list):\n",
        "    file = os.path.join(video_folder, file_name)\n",
        "    with open(file, 'w', encoding='utf-8') as f:\n",
        "        for qa in qa_list:\n",
        "            f.write(qa + '\\n')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    tool_num = {}\n",
        "    for i in [18]:\n",
        "        print(f'processing file {i}')\n",
        "        QA_folder = r'D:\\MSc Dataset\\Annotaion18193335\\QA'\n",
        "        video_num = 'video_' + f\"{i:03d}\"\n",
        "        video_folder = os.path.join(QA_folder, video_num)\n",
        "\n",
        "        instrument_folder = r'D:\\MSc Dataset\\Annotaion18193335\\instruments'\n",
        "        instrument_num = 'instruments_' + f\"{i:03d}\" + '.csv'\n",
        "        instrument_file = os.path.join(instrument_folder, instrument_num)\n",
        "\n",
        "        step_folder = r'D:\\MSc Dataset\\Annotaion18193335\\steps'\n",
        "        step_num = 'steps_' + f\"{i:03d}\" + '.csv'\n",
        "        step_file = os.path.join(step_folder, step_num)\n",
        "\n",
        "        # open instrument file\n",
        "        instrument_df = pd.read_csv(instrument_file)\n",
        "        # open step file\n",
        "        step_df = pd.read_csv(step_file)\n",
        "        int_time_list = list(step_df['int_time'])\n",
        "\n",
        "        # go through video folder\n",
        "        for idx, file_name in enumerate(os.listdir(video_folder)):  # 遍历video_01下的所有txt文件; 0, 00000.txt; 自动忽略第一行\n",
        "            # instrument csv file\n",
        "            instrument_row = instrument_df.iloc[idx]  # 第idx+1行\n",
        "            num_of_tool = get_num_of_tool(instrument_row)\n",
        "\n",
        "            if (instrument_row['str_instrument1'] == 'out_of_patient' or\n",
        "                    instrument_row['str_instrument2'] == 'out_of_patient'):\n",
        "                continue\n",
        "\n",
        "            # step csv file\n",
        "            step_name = get_current_step_name(step_df, int_time_list, idx).replace('\\u3000', ' ').strip().lower()\n",
        "            print(f'step_name: {step_name}')\n",
        "            if(step_name == 'nasal corridor creation'):\n",
        "                print(\"yes\")\n",
        "            if step_name in ['out_of_patient', 'operation_not_started', 'operation_ended']:\n",
        "                continue\n",
        "\n",
        "            # print(f'index: {idx}')\n",
        "            if num_of_tool == 0:\n",
        "\n",
        "                if num_of_tool not in tool_num:\n",
        "                    tool_num[num_of_tool] = 1\n",
        "                else:\n",
        "                    tool_num[num_of_tool] += 1\n",
        "\n",
        "                phase_qa_str, current_phase = prepare_what_phase_qa(step_name)  # 3\n",
        "                step_qa_str = prepare_what_step_qa(step_name)  # 14\n",
        "\n",
        "                next_phase_qa_str = prepare_next_phase_qa(current_phase)\n",
        "                next_step_qa_str = prepare_next_step_qa(step_name)\n",
        "\n",
        "                how_many_tool_qa_str = prepare_how_many_tool_qa(num_of_tool)\n",
        "\n",
        "                qa_list = [phase_qa_str, step_qa_str, next_phase_qa_str, next_step_qa_str, how_many_tool_qa_str]\n",
        "                write_file(video_folder, file_name, qa_list)\n",
        "                questions += 5\n",
        "                frames += 1\n",
        "\n",
        "            if num_of_tool == 1:\n",
        "\n",
        "                if num_of_tool not in tool_num:\n",
        "                    tool_num[num_of_tool] = 1\n",
        "                else:\n",
        "                    tool_num[num_of_tool] += 1\n",
        "\n",
        "                phase_qa_str, current_phase = prepare_what_phase_qa(step_name)\n",
        "                step_qa_str = prepare_what_step_qa(step_name)\n",
        "                operation_qa_str, operation = prepare_what_operation_qa(step_name)  # 0没有的\n",
        "\n",
        "                next_phase_qa_str = prepare_next_phase_qa(current_phase)\n",
        "                next_step_qa_str = prepare_next_step_qa(step_name)\n",
        "\n",
        "                what_tool_qa_str = prepare_what_tool_qa_one(instrument_row)  # 0没有的\n",
        "                tool_operation_qa_str = prepare_tool_operation_qa(instrument_row, operation)\n",
        "                where_tool_qa_str = prepare_where_tool_qa(instrument_row)\n",
        "\n",
        "                how_many_tool_qa_str = prepare_how_many_tool_qa(num_of_tool)\n",
        "\n",
        "                qa_list = [phase_qa_str, step_qa_str, operation_qa_str, next_phase_qa_str, next_step_qa_str,\n",
        "                           what_tool_qa_str, tool_operation_qa_str, where_tool_qa_str, how_many_tool_qa_str]\n",
        "                write_file(video_folder, file_name, qa_list)\n",
        "                questions += 9\n",
        "                frames += 1\n",
        "\n",
        "            if num_of_tool == 2:\n",
        "\n",
        "                if num_of_tool not in tool_num:\n",
        "                    tool_num[num_of_tool] = 1\n",
        "                else:\n",
        "                    tool_num[num_of_tool] += 1\n",
        "\n",
        "                phase_qa_str, current_phase = prepare_what_phase_qa(step_name)\n",
        "                step_qa_str = prepare_what_step_qa(step_name)\n",
        "                operation_qa_str, operation = prepare_what_operation_qa(step_name)\n",
        "\n",
        "                next_phase_qa_str = prepare_next_phase_qa(current_phase)\n",
        "                next_step_qa_str = prepare_next_step_qa(step_name)\n",
        "\n",
        "                what_tool_qa_str_1 = prepare_what_tool_qa_two(instrument_row, col_num=1)\n",
        "                what_tool_qa_str_2 = prepare_what_tool_qa_two(instrument_row, col_num=2)\n",
        "\n",
        "                tool_operation_qa_str_1 = prepare_tool_operation_qa_two(instrument_row, operation, col_num=1)\n",
        "                tool_operation_qa_str_2 = prepare_tool_operation_qa_two(instrument_row, operation, col_num=2)\n",
        "\n",
        "                where_tool_qa_str_1 = prepare_where_tool_qa_two(instrument_row, col_num=1)\n",
        "                where_tool_qa_str_2 = prepare_where_tool_qa_two(instrument_row, col_num=2)\n",
        "\n",
        "                how_many_tool_qa_str = prepare_how_many_tool_qa(num_of_tool)\n",
        "\n",
        "                qa_list = [phase_qa_str, step_qa_str, operation_qa_str, next_phase_qa_str, next_step_qa_str,\n",
        "                           what_tool_qa_str_1, what_tool_qa_str_2, tool_operation_qa_str_1, tool_operation_qa_str_2,\n",
        "                           where_tool_qa_str_1, where_tool_qa_str_2, how_many_tool_qa_str]\n",
        "                write_file(video_folder, file_name, qa_list)\n",
        "                questions += 12\n",
        "                frames += 1\n",
        "\n",
        "        print(count_dict)\n",
        "        print(f'video_{i} finished.')\n",
        "\n",
        "    print(tool_num)\n",
        "\n",
        "    print(f'number of frames: {frames}')\n",
        "    print(f'number of questions: {questions}')\n",
        "    print(f'sum of dict: {sum(count_dict.values())}')\n"
      ],
      "metadata": {
        "id": "HFz-q8yQuqKs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}